{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from textatistic import Textatistic\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r\"([A-Z][A-Z0-9.]+|[0-9]+[,.][0-9]+|[cdjlmnst]'|qu'|[\\w'-]+|\\S)\")\n",
    "\n",
    "def ouvrir_json(chemin):\n",
    "    f = open(chemin, encoding=\"utf-8\")\n",
    "    toto = json.load(f)\n",
    "    f.close()\n",
    "    return toto\n",
    "def ecrire_json(chemin, contenu):\n",
    "    w    = open(chemin, \"w\", encoding=\"utf-8\")\n",
    "    w.write(json.dumps(contenu, indent=2, ensure_ascii=False))\n",
    "    w.close()\n",
    "    \n",
    "def combien_caracteres(texte):\n",
    "    return len(texte)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def combien_phrases(texte):\n",
    "    return len(sent_tokenize(texte, \"french\"))\n",
    "\n",
    "def compter_mots(texte):\n",
    "    mots = tokenizer.tokenize(texte)\n",
    "    return len(mots)\n",
    "\n",
    "def mesurer_phrases(texte):\n",
    "    d = {}\n",
    "    for phrase in sent_tokenize(texte, \"french\"):\n",
    "        if phrase not in d:\n",
    "            d[phrase] = len(phrase)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On traite 1249 fichiers\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "liste_fichier = glob.glob(\"/Users/mustapha/Documents/GitHub/28002878/Lyrics_all/*\")\n",
    "print(\"On traite %i fichiers\"%len(liste_fichier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos=[]\n",
    "artistes=[]\n",
    "paroles_all=\"\"\n",
    "parole_allsongs=[]\n",
    "for path in sorted(liste_fichier):\n",
    "    d = dict(ouvrir_json(path))\n",
    "    chansons = d.get(\"songs\")\n",
    "    artiste = d.get(\"name\")\n",
    "    artistes.append(artiste)\n",
    "    for l in chansons:\n",
    "        if l[\"lyrics\"] != None:\n",
    "            paroles = l[\"lyrics\"]\n",
    "           # print((len(paroles))\n",
    "            parole_allsongs.append(paroles)\n",
    "            clean_paroles = re.sub(\"\\n\", \". \", paroles)\n",
    "            paroles_all+=clean_paroles\n",
    "\n",
    "            \n",
    "\n",
    "nbParoles = len(parole_allsongs)\n",
    "nbChar = len(paroles_all)\n",
    "nbMots = compter_mots(paroles_all)\n",
    "nbPhrase = combien_phrases(paroles_all)\n",
    "infos.append({\"statistique_all_data\":{\"nombre d'artistes\" :len(artistes),\n",
    "                                      \"nombre des chansons avec paroles\" : nbParoles,                           \n",
    "                                      \"nombre de caractères\": nbChar,\n",
    "                                      \"moyenne de caractères par chanson\" : nbChar/nbParoles,\n",
    "                                      \"nombre de mots\": nbMots,\n",
    "                                      \"moyenne de mots par chanson\" : nbMots/nbParoles,\n",
    "                                      \"nombre de phrases\": nbPhrase,\n",
    "                                      \"moyenne de phrases par chanson\" : nbPhrase/nbParoles,\n",
    "                                      \"moyenne de mots par phrase\" : nbMots/nbPhrase}})\n",
    "\n",
    "ecrire_json(\"/Users/mustapha/Documents/GitHub/Memoire/infos&stats/statistique_all_data.json\",infos) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17791"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parole_allsongs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
