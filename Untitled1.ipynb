{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def ouvrir_json(chemin):\n",
    "  f = open(chemin, encoding=\"utf-8\")\n",
    "  toto = json.load(f)\n",
    "  f.close()\n",
    "  return toto\n",
    "\n",
    "def ecrire_fichier(chemin, contenu):\n",
    "  w = open(chemin, \"w\", encoding=\"utf-8\")\n",
    "  w.write(contenu)\n",
    "  w.close()\n",
    "def lire_fichier(chemin):\n",
    "  f = open(chemin, \"r\", encoding=\"utf-8\")\n",
    "  chaine = f.read()\n",
    "  f.close()\n",
    "  return chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_genius1 = ouvrir_json(\"Data/echantillon1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "echantillon1=data_genius1.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paroles_data1 = []\n",
    "\n",
    "\n",
    "\n",
    "for child in echantillon1:\n",
    "    for parole in child:\n",
    "        paroles = parole.get(\"lyrics\")\n",
    "        paroles_data1.append(paroles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_sm = spacy.load(\"fr_core_news_sm\")\n",
    "nlp_md = spacy.load(\"fr_core_news_md\")\n",
    "nlp_lg = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"Je m'appelle Mustapha je vien de la wilaya de Sidi Bel-Abbès, c'est une belle ville\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=nlp_sm(sentence)\n",
    "md=nlp_md(sentence)\n",
    "lg=nlp_lg(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.span.Span' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a8a1e384a56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"LOC\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NOUN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "for word in sm:\n",
    "    for word in sm.ents:\n",
    "        if word.label_ ==\"LOC\" and word.pos_ == \"NOUN\":\n",
    "            print(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.span.Span' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c80c86e8e3a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#if entity.label_ ==\"LOC\" and entity.pos_ == \"NOUN\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#if entity.pos_ ==\"NOUN\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;31m#print(entity.text, entity.label_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "for entity in sm and sm.ents:\n",
    "    print(entity.text, entity.pos_)\n",
    "    #if entity.label_ ==\"LOC\" and entity.pos_ == \"NOUN\":\n",
    "        #if entity.pos_ ==\"NOUN\":\n",
    "            #print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je m'appelle Mustapha je viens de la wilaya de Sidi Bel-Abbés, c'est une belle ville d'Algérie\n"
     ]
    }
   ],
   "source": [
    "for sent in sm.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mustapha \n",
      " LOC\n",
      " Non-GPE locations, mountain ranges, bodies of water\n",
      "Sidi Bel \n",
      " PER\n",
      " Named person or family.\n",
      "Abbés \n",
      " PER\n",
      " Named person or family.\n",
      "Algérie \n",
      " LOC\n",
      " Non-GPE locations, mountain ranges, bodies of water\n"
     ]
    }
   ],
   "source": [
    "for entity in sm.ents:\n",
    "    print(entity.text +' \\n ' + entity.label_ + '\\n ' + str(spacy.explain(entity.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je\n",
      "je\n",
      "de Sidi Bel-Abbés\n",
      "d'Algérie\n"
     ]
    }
   ],
   "source": [
    "for noun in sm.noun_chunks:\n",
    "    print(noun.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je être un aventurier \n",
      " et je avoir beaucoup bourlinguer \n",
      " je avoir faire le vie à varsovie \n",
      " je avoir faire le mort à Baltimore \n",
      " je avoir faire le rat à Camberra \n",
      " je avoir jouer à dé à Yaoundé \n",
      " je avoir jouer à dame à amsterdam \n",
      " je avoir faire un game à Binningham \n",
      " je être un aventurier \n",
      " avec lequel il falloir compter \n",
      " je être un aventurier \n",
      " avec lequel il falloir compter \n",
      "\n",
      " je avoir être à Bornéo \n",
      " je avoir être pompette à Papeete \n",
      " je avoir bu de le eau à Bordeaux \n",
      " je avoir dire tant pis à Tampico \n",
      " je avoir faire le soldat à Bogola \n",
      " et de calcul à Calcutta \n",
      "\n",
      " à moi , falloir pas me en raconter \n",
      " parce que , vraiment , je en avoir bavé \n",
      " à moi , falloir pas me en raconter \n",
      " parce que , vraiment , je en avoir bavé \n",
      "\n",
      " je avoir être errer à Téhéran \n",
      " et au sana à Saana \n",
      " je avoir faire le chasseur à Kinshassa \n",
      " et le nounou à Cotonou \n",
      " je avoir faire de le tôle à dôle \n",
      " je avoir être lourder à Lourdes \n",
      "\n",
      " je être un aventurier \n",
      " J' en avoir vrairnent beaucoup bavé \n",
      " je être un aventurier \n",
      " J' en avoir vrairnent beaucoup bavé \n",
      "\n",
      " je avoir être crétin à Créteil \n",
      " je avoir avoir le ber1ue à berlin \n",
      " je avoir être gentil à port-gentil \n",
      " et malpoli à Tripoli \n",
      " je avoir faire le vie à varsovie \n",
      " et le mort à Baltimore \n",
      "\n",
      " je être un aventurier \n",
      " maintenant , ce être terminer \n",
      " je être un aventurier \n",
      " maintenant , ce être terminer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "new = \" \".join([token.lemma_ for token in sm])\n",
    "print(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_sm=[]\n",
    "for entity in lol.ents:\n",
    "    if entity.label_ ==\"LOC\":\n",
    "        loc_sm.append(entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baltimore', 'Yaoundé', 'Bornéo', 'Papeete', 'Bordeaux', 'Tampico', 'Calcutta', 'Saana', 'Kinshassa', 'Cotonou', 'Lourdes', 'Créteil', 'ber1ue', 'Tripoli', 'Baltimore']\n"
     ]
    }
   ],
   "source": [
    "print(loc_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'spacy.tokens.token.Token' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d162880b9014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' --> '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'spacy.tokens.token.Token' and 'str'"
     ]
    }
   ],
   "source": [
    "for token in sm:\n",
    "    print(token + ' --> ' + stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_sm=[]\n",
    "loc_md=[]\n",
    "loc_lg=[]\n",
    "doc_sm= nlp_sm(str(sm))\n",
    "for entity in doc_sm.ents:\n",
    "    if entity.label_ ==\"LOC\":\n",
    "        loc_sm.append(entity.text)\n",
    "doc_md= nlp_md(str(sm))\n",
    "for entity in doc_md.ents:\n",
    "    if entity.label_ ==\"LOC\":\n",
    "        loc_md.append(entity.text)\n",
    "doc_lg= nlp_lg(str(sm))\n",
    "for entity in doc_lg.ents:\n",
    "    if entity.label_ ==\"LOC\":\n",
    "        loc_lg.append(entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baltimore', 'Yaoundé', 'Bornéo', 'Papeete', 'Bordeaux', 'Tampico', 'Calcutta', 'Saana', 'Kinshassa', 'Cotonou', 'Lourdes', 'Créteil', 'ber1ue', 'Tripoli', 'Baltimore']\n"
     ]
    }
   ],
   "source": [
    "print(loc_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"J'\", 'Varsovie', 'Baltimore', 'Yaoundé', 'Amsterdam', \"J'ai fait des games\", 'Bornéo', 'Papeete', \"J'ai bu de l'eau\", 'Bordeaux', 'Tampico', 'Calcutta', 'A', 'Téhéran', 'Saana', 'Kinshassa', 'Dôle', 'Lourdes', \"J'\", \"J'\", 'Créteil', \"J'ai eu la ber1ue\", \"J'\", 'Port-Gentil', 'Tripoli', 'Varsovie', 'Baltimore', 'Maintenant']\n"
     ]
    }
   ],
   "source": [
    "print(loc_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baltimore', 'Yaoundé', 'Binningham', 'Bornéo', 'Papeete', 'Bordeaux', 'Tampico', 'Calcutta \\n\\n ', 'Téhéran', 'Saana', 'Cotonou', 'Lourdes', 'Créteil', 'Tripoli', 'Baltimore']\n"
     ]
    }
   ],
   "source": [
    "print(loc_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Varsovie', 'Baltimore', 'Yaoundé', 'Amsterdam', 'Binningham', 'Bornéo', 'Papeete', 'Bordeaux', 'Tampico', \"J'ai fait l'soldat\", 'Calcutta', 'Téhéran', 'Saana', 'Cotonou', 'Dôle', 'Lourdes', 'Créteil', 'Port-Gentil', 'Tripoli', 'Varsovie', 'Baltimore']\n"
     ]
    }
   ],
   "source": [
    "print(loc_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baltimore', 'Yaoundé', 'Binningham', 'Bornéo', 'Papeete', 'Bordeaux', 'Tampico', 'Calcutta', 'Téhéran', 'Saana', 'Cotonou', 'Lourdes', 'Créteil', 'Tripoli', 'Baltimore']\n"
     ]
    }
   ],
   "source": [
    "print(loc_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Varsovie', 'Baltimore', 'Yaoundé', 'Amsterdam', 'Bornéo', 'Papeete', 'Bordeaux', 'Tampico', 'Calcutta', 'Téhéran', 'Saana', 'Cotonou', 'Dôle', 'Lourdes', 'Créteil', 'Port-Gentil', 'Tripoli', 'Varsovie', 'Baltimore']\n"
     ]
    }
   ],
   "source": [
    "print(loc_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1_corpus = [\"J'\", 'Varsovie', 'Baltimore', 'Yaoundé', 'Amsterdam', \"J'ai fait des games\", 'Bornéo', 'Papeete', \"J'ai bu de l'eau\", 'Bordeaux', 'Tampico', 'Calcutta', 'A', 'Téhéran', 'Saana', 'Kinshassa', 'Dôle', 'Lourdes', \"J'\", \"J'\", 'Créteil', \"J'ai eu la ber1ue\", \"J'\", 'Port-Gentil', 'Tripoli', 'Varsovie', 'Baltimore', 'Maintenant']\n",
    "loc2_corpus = ['Varsovie', 'Baltimore', 'Yaoundé', 'Amsterdam', 'Binningham', 'Bornéo', 'Papeete', 'Bordeaux', 'Tampico', \"J'ai fait l'soldat\", 'Calcutta', 'Téhéran', 'Saana', 'Cotonou', 'Dôle', 'Lourdes', 'Créteil', 'Port-Gentil', 'Tripoli', 'Varsovie', 'Baltimore']\n",
    "loc3_corpus = ['Varsovie', 'Baltimore', 'Yaoundé', 'Amsterdam', 'Bornéo', 'Papeete', 'Bordeaux', 'Tampico', 'Calcutta', 'Téhéran', 'Saana', 'Cotonou', 'Dôle', 'Lourdes', 'Créteil', 'Port-Gentil', 'Tripoli', 'Varsovie', 'Baltimore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lieux en commun:  {'Saana', 'Tampico', 'Cotonou', 'Papeete', 'Yaoundé', 'Bornéo', 'Tripoli', 'Bordeaux', 'Baltimore', 'Créteil', 'Lourdes'}\n"
     ]
    }
   ],
   "source": [
    "lieux_en_commun = set(loc_sm).intersection(set(loc_md), set(loc_lg))\n",
    "print(\"lieux en commun: \" ,lieux_en_commun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans lieux1 {'Kinshassa', 'ber1ue'}\n"
     ]
    }
   ],
   "source": [
    "print(\"dans lieux1\", set(loc_sm).difference(set(loc_md), set(loc_lg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans lieux2 set()\n"
     ]
    }
   ],
   "source": [
    "print(\"dans lieux2\", set(loc_md).difference(set(loc_md), set(loc_sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans lieux3 {'Calcutta \\n\\n '}\n"
     ]
    }
   ],
   "source": [
    "print(\"dans lieux3\", set(loc_md).difference(set(loc_lg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
